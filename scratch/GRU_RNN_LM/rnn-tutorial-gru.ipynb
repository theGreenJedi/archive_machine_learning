{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU RNN Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano as theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import operator\n",
    "from utils import load_data, load_model_parameters_theano, generate_sentences\n",
    "from gru_theano import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file...\n",
      "Parsed 502183 sentences.\n",
      "Found 193212 unique words tokens.\n",
      "Using vocabulary size 8000.\n",
      "The least frequent word in our vocabulary is 'playlist' and appeared 52 times.\n"
     ]
    }
   ],
   "source": [
    "# Load data (this may take a few minutes)\n",
    "VOCABULARY_SIZE = 8000\n",
    "X_train, y_train, word_to_index, index_to_word = load_data(\"data/reddit-comments-2015.csv\", VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model model from ./data/pretrained.npz with hidden_dim=128 word_dim=8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_theano.py:112: UserWarning: The Param class is deprecated. Replace Param(default=N) by theano.In(value=N)\n",
      "  [x, y, learning_rate, theano.Param(decay, default=0.9)],\n"
     ]
    }
   ],
   "source": [
    "# Load parameters of pre-trained model\n",
    "model = load_model_parameters_theano('./data/pretrained.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build your own model (not recommended unless you have a lot of time!)\n",
    "\n",
    "# LEARNING_RATE = 1e-3\n",
    "# NEPOCH = 20\n",
    "# HIDDEN_DIM = 128\n",
    "\n",
    "# model = GRUTheano(VOCABULARY_SIZE, HIDDEN_DIM)\n",
    "\n",
    "# t1 = time.time()\n",
    "# model.sgd_step(X_train[0], y_train[0], LEARNING_RATE)\n",
    "# t2 = time.time()\n",
    "# print \"SGD Step time: ~%f milliseconds\" % ((t2 - t1) * 1000.)\n",
    "\n",
    "# train_with_sgd(model, X_train, y_train, LEARNING_RATE, NEPOCH, decay=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i ca n't ultimately last i had to keep the brain of the death .\n",
      "bored capitalism back was better to be harsh .\n",
      "i understand how he took !\n",
      "he ending up the project sent .\n",
      "my god , me , etc .\n",
      "what do you mean , so you 'll try with that .\n",
      "that 's it though .\n",
      "it looked nice .\n",
      "it makes sense when it comes to mind and we lord fall eliminate .\n",
      "thus , they make all of pr illegal .\n"
     ]
    }
   ],
   "source": [
    "generate_sentences(model, 10, index_to_word, word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more semantic and syntactic structure than Vanillar RNN Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of optimzing the code, the perhaps most important one would be to batch together weight-updates. Instead of learning from one sentence at a time, we need to group sentences of the same length (or even pad all sentences to have the same length) and then perform large matrix multiplizations and sum up gradients for the whole batch. That's because such large matrix multiplications are efficiently handled by a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

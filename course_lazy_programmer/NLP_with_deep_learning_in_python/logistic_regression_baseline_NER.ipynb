{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'theano'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82b0617366d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mpos_baseline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\user\\Documents\\GitHub\\deep_learning_archieves\\course_lazy_programmer\\NLP_with_deep_learning_in_python\\pos_baseline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'theano'"
     ]
    }
   ],
   "source": [
    "# Course URL:\n",
    "# https://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-python\n",
    "# https://udemy.com/natural-language-processing-with-deep-learning-in-python\n",
    "\n",
    "# data from https://github.com/aritter/twitter_nlp/blob/master/data/annotated/ner.txt\n",
    "# data2 from http://schwa.org/projects/resources/wiki/Wikiner#WikiGold\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from pos_baseline import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(split_sequences=False):\n",
    "    word2idx = {}\n",
    "    tag2idx = {}\n",
    "    word_idx = 0\n",
    "    tag_idx = 0\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    for line in open('ner.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            r = line.split()\n",
    "            word, tag = r\n",
    "            word = word.lower()\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = word_idx\n",
    "                word_idx += 1\n",
    "            currentX.append(word2idx[word])\n",
    "            \n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1\n",
    "            currentY.append(tag2idx[tag])\n",
    "        elif split_sequences:\n",
    "            Xtrain.append(currentX)\n",
    "            Ytrain.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "\n",
    "    if not split_sequences:\n",
    "        Xtrain = currentX\n",
    "        Ytrain = currentY\n",
    "\n",
    "    print \"number of samples:\", len(Xtrain)\n",
    "    Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "    Ntest = int(0.3*len(Xtrain))\n",
    "    Xtest = Xtrain[:Ntest]\n",
    "    Ytest = Ytrain[:Ntest]\n",
    "    Xtrain = Xtrain[Ntest:]\n",
    "    Ytrain = Ytrain[Ntest:]\n",
    "    print \"number of classes:\", len(tag2idx)\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx\n",
    "\n",
    "\n",
    "# def get_data2(split_sequences=False):\n",
    "#     word2idx = {}\n",
    "#     tag2idx = {}\n",
    "#     word_idx = 0\n",
    "#     tag_idx = 0\n",
    "#     Xtrain = []\n",
    "#     Ytrain = []\n",
    "#     for line in open('../large_files/aij-wikiner-en-wp3'):\n",
    "#         # each line is a full sentence\n",
    "#         currentX = []\n",
    "#         currentY = []\n",
    "#         line = line.rstrip()\n",
    "#         if not line:\n",
    "#             continue\n",
    "#         triples = line.split()\n",
    "#         for triple in triples:\n",
    "#             word, _, tag = triple.split('|')\n",
    "#             if word not in word2idx:\n",
    "#                 word2idx[word] = word_idx\n",
    "#                 word_idx += 1\n",
    "#             currentX.append(word2idx[word])\n",
    "            \n",
    "#             if tag not in tag2idx:\n",
    "#                 tag2idx[tag] = tag_idx\n",
    "#                 tag_idx += 1\n",
    "#             currentY.append(tag2idx[tag])\n",
    "\n",
    "#         Xtrain.append(currentX)\n",
    "#         Ytrain.append(currentY)\n",
    "\n",
    "#     if not split_sequences:\n",
    "#         Xtrain = np.concatenate(Xtrain)\n",
    "#         Ytrain = np.concatenate(Ytrain)\n",
    "\n",
    "#     print \"number of samples:\", len(Xtrain)\n",
    "#     Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "#     Ntest = int(0.3*len(Xtrain))\n",
    "#     Xtest = Xtrain[:Ntest]\n",
    "#     Ytest = Ytrain[:Ntest]\n",
    "#     Xtrain = Xtrain[Ntest:]\n",
    "#     Ytrain = Ytrain[Ntest:]\n",
    "#     print \"number of classes:\", len(tag2idx)\n",
    "#     return Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx\n",
    "\n",
    "\n",
    "def main():\n",
    "    Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx = get_data()\n",
    "\n",
    "    V = len(word2idx)\n",
    "    print \"vocabulary size:\", V\n",
    "    K = len(tag2idx)\n",
    "\n",
    "    # train and score\n",
    "    model = LogisticRegression()\n",
    "    model.fit(Xtrain, Ytrain, V=V, K=K, epochs=5)\n",
    "    print \"training complete\"\n",
    "    print \"train score:\", model.score(Xtrain, Ytrain)\n",
    "    print \"train f1 score:\", model.f1_score(Xtrain, Ytrain)\n",
    "    print \"test score:\", model.score(Xtest, Ytest)\n",
    "    print \"test f1 score:\", model.f1_score(Xtest, Ytest)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

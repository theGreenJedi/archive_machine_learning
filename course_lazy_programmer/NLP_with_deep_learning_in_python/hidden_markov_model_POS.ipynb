{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Course URL:\n",
    "# https://deeplearningcourses.com/c/natural-language-processing-with-deep-learning-in-python\n",
    "# https://udemy.com/natural-language-processing-with-deep-learning-in-python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from hmmd_scaled import HMM\n",
    "\n",
    "from pos_baseline import get_data\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.973753937854\n",
      "test accuracy: 0.928784009118\n",
      "train f1: 0.923527954605\n",
      "test f1: 0.862609207175\n"
     ]
    }
   ],
   "source": [
    "def accuracy(T, Y):\n",
    "    # inputs are lists of lists\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    for t, y in zip(T, Y):\n",
    "        n_correct += np.sum(t == y)\n",
    "        n_total += len(y)\n",
    "    return float(n_correct) / n_total\n",
    "\n",
    "\n",
    "def total_f1_score(T, Y):\n",
    "    # inputs are lists of lists\n",
    "    T = np.concatenate(T)\n",
    "    Y = np.concatenate(Y)\n",
    "    return f1_score(T, Y, average=None).mean()\n",
    "\n",
    "\n",
    "# def flatten(l):\n",
    "#     return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def main(smoothing=10e-2):\n",
    "    # X = words, Y = POS tags\n",
    "    Xtrain, Ytrain, Xtest, Ytest, word2idx = get_data(split_sequences=True)\n",
    "    V = len(word2idx) + 1\n",
    "\n",
    "    # find hidden state transition matrix and pi\n",
    "    M = max(max(y) for y in Ytrain) + 1 #len(set(flatten(Ytrain)))\n",
    "    A = np.ones((M, M))*smoothing # add-one smoothing\n",
    "    pi = np.zeros(M)\n",
    "    for y in Ytrain:\n",
    "        pi[y[0]] += 1\n",
    "        for i in xrange(len(y)-1):\n",
    "            A[y[i], y[i+1]] += 1\n",
    "    # turn it into a probability matrix\n",
    "    A /= A.sum(axis=1, keepdims=True)\n",
    "    pi /= pi.sum()\n",
    "\n",
    "    # find the observation matrix\n",
    "    B = np.ones((M, V))*smoothing # add-one smoothing\n",
    "    for x, y in zip(Xtrain, Ytrain):\n",
    "        for xi, yi in zip(x, y):\n",
    "            B[yi, xi] += 1\n",
    "    B /= B.sum(axis=1, keepdims=True)\n",
    "\n",
    "    hmm = HMM(M)\n",
    "    hmm.pi = pi\n",
    "    hmm.A = A\n",
    "    hmm.B = B\n",
    "\n",
    "    # get predictions\n",
    "    Ptrain = []\n",
    "    for x in Xtrain:\n",
    "        p = hmm.get_state_sequence(x)\n",
    "        Ptrain.append(p)\n",
    "\n",
    "    Ptest = []\n",
    "    for x in Xtest:\n",
    "        p = hmm.get_state_sequence(x)\n",
    "        Ptest.append(p)\n",
    "\n",
    "    # print results\n",
    "    print \"train accuracy:\", accuracy(Ytrain, Ptrain)\n",
    "    print \"test accuracy:\", accuracy(Ytest, Ptest)\n",
    "    print \"train f1:\", total_f1_score(Ytrain, Ptrain)\n",
    "    print \"test f1:\", total_f1_score(Ytest, Ptest)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
